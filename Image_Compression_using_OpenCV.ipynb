{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZAG7z9epROc"
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai/\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Logo/SNLogo.png\" width=\"200\" align=\"center\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1r_4lmwqDMA"
   },
   "source": [
    "<h1>Lab - Image Compression and Color Quantization using K Means Clustering</h1>\n",
    "<p><b>Welcome!</b> This lab is about compressing the size of images using a technique called K Means Clustering. We will compress images using K Means Clustering in the Python Programming Language. After completing this lab, you will:</p>\n",
    "<h5> 1. Learn to download and read images using OpenCV </h5>\n",
    "<h5> 2. Know about image compression and its Importance </h5>\n",
    "<h5> 3. Compress image sizes by up to 90%!! </h5>\n",
    "<h5> 4. Compress images using a technique called K Means Clustering</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <br>\n",
    "    <br>\n",
    "    <h2>Table of Contents</h2>\n",
    "    <ul>\n",
    "        <li><a href=\"#ref0\">What is an image comprised of?</a></li>\n",
    "        <li><a href=\"#ref1\">Image Compression and its importance</a></li>\n",
    "        <li><a href=\"#ref2\">What is K Means Clustering</a></li>\n",
    "        <li><a href=\"#ref3\">Compressing Images using K Means Clustering</a></li>\n",
    "        <li><a href=\"#ref4\">Exercises</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <p>Estimated Time Needed: <strong>1 hr 30 min</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref0\"></a>\n",
    "<h2 align=\"center\">What is an image comprised of?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The basic building block of any picture is a pixel. If we zoom in on any picture, we can start to see the pixels and the pixels the image is comprised of.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's start by downloading an image of a bunny. We will use the same technique to download an image as we learnt in the lab of Classifying Images using IBM Watson Visual Recognition in Python</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing OpenCV and urllib for downloading and displaying the bunny image\n",
    "import urllib.request\n",
    "import cv2\n",
    "bunny_image_url = \"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/bunny.png\"\n",
    "urllib.request.urlretrieve(bunny_image_url, \"bunny.png\") # downloads file as \"bunny.png\"\n",
    "im = cv2.imread(\"bunny.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HepNP_F369Pu"
   },
   "outputs": [],
   "source": [
    "# loading standard python modules\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2279,
     "status": "ok",
     "timestamp": 1555278102923,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "DOpoC4FZ4ipy",
    "outputId": "3d6da700-df8b-4b55-8697-603f562a870e"
   },
   "outputs": [],
   "source": [
    "# We read a bunny image here and display it\n",
    "img_corrected = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(img_corrected)\n",
    "print(\"Original size of bunny's image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('bunny.png').st_size)/1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3gRyd2v-8gn"
   },
   "source": [
    "<b>What is a pixel?</b>\n",
    "<p>To form any visible color, we need the three primary colors (i.e Red, Green and Blue). Mixing these colors in various proportions provides us with all colors of the visible spectrum. Interpreting this in the computer's technology, each pixel is comprised of 3 channels - i.e. Red, Green and Blue. Each of these channels has an intensity value that ranges between 0 - 255. From combinatorics we know that the total number of colors we can represent in each pixel are 256 x 256 x 256. Since each channel in a pixel can have 256 = 2^8 possible values, each channel requires 8 bits of memory to store in computer memory. Thus, each pixel requires 8 + 8 + 8 = 24 bits of memory for storage</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFbGCFSWypxw"
   },
   "source": [
    "<p>Now, let's focus on the bunny's image. The image has a total of 209960 pixels and since each pixel required 24 bits to store, the image has an original size of 209960 x 24 bits. Doing some math magic, in Kilo Bytes this is equal to ((209960 x 24) / 8) / 1000 ~ 630 Kilo Bytes</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2 align=\"center\">Image Compression and its Importance</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbXYO1Sq9Kcr"
   },
   "source": [
    "<p>Image compression is about compressing the size of images. This is important since we can store these images more efficiently and save space, bandwidth and time of the computer network. Further, this would also save money to store images on computers and phones since a lot more images can now be stored (due to their compressed size) with the same amount of storage space. We will compress the size of the images using a technique called K - Means clustering.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2 align=\"center\">What is K Means Clustering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81MAhehlzUez"
   },
   "source": [
    "<p>As the name suggests, K Means Clustering is a technique by which we can split a bunch of data points into various clusters (specifically K clusters). The data points are clustered together based upon a certain similarity. K here represents the number of clusters the data points are split into. The \"Means\" in K Means refers to finding the centroid of each of the K clusters. Run the code cell below to see a visual representation of running K Means clustering technique on a bunch of randomly generated data points:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1555007015838,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "u4fIWzBT_GxH",
    "outputId": "1eea733c-7e00-4ccf-9d3e-e60038cb6608"
   },
   "outputs": [],
   "source": [
    "k_means_url = \"http://i.stack.imgur.com/cIDB3.png\"\n",
    "urllib.request.urlretrieve(k_means_url, \"K_Means_clustering.png\") # downloads file as \"K_Means_clustering.png\"\n",
    "k_means_im = cv2.imread(\"K_Means_clustering.png\")\n",
    "k_means_im_corrected = cv2.cvtColor(k_means_im, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(k_means_im_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrLPNGJV_Yky"
   },
   "source": [
    "<p>To perform K Means clustering we have the following steps:</p>\n",
    "<0l>\n",
    "    <li>Initially choose K points amongst the given set of data points. These K points represent the centroids of the K clusters</li>\n",
    "    <li>Next, assign each data point to the cluster whose center is nearest to it</li>\n",
    "    <li>New centroids are calculated for each of the K clusters based upon the data points that are assigned in that cluster</li>\n",
    "</ol>\n",
    "<br>\n",
    "<p>Step 2 and 3 are repeated until the centroids stop moving or the defined number of iterations are completed. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VvRW8kODn77"
   },
   "source": [
    "<p>For our use case of image compression, our data points are the pixels in our image, and we are trying to group pixels of similar color in K clusters (for e.g. K = 8 clusters) i.e. 8 different colors. Thus, instead of each pixel originally representing 256 x 256 x 256 colors, each pixel can now only represent 8 possible colors. Therefore, each pixel now only requires 3 bits of memory for storage (since 2^3 = 8) instead of the original 24 bits. This technique of breaking all possible colors of the RGB color space over K colors is called <b>Color Quantization</b>.</p> \n",
    "<p>The K centroids of the clusters are representative of the three dimensional RGB color space and would replace the colors of all points in their cluster and thus the image will only have K colors in it.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaPS5EliefSo"
   },
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<h2 align=\"center\">Compressing Images using K Means Clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_Vyp9Vgk-fc"
   },
   "outputs": [],
   "source": [
    "# We are using the sklearn python module and are importing the in built KMeans\n",
    "# function from it\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvhi3kP0lrBt"
   },
   "outputs": [],
   "source": [
    "# we import numpy here to transform image dimensions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6MQ-dn_l_9D"
   },
   "outputs": [],
   "source": [
    "# Extracting num_rows and num_cols from bunny's image (stored in im variable)\n",
    "num_rows = im.shape[0]\n",
    "num_cols = im.shape[1]\n",
    "transform_image_for_KMeans = im.reshape(num_rows * num_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGiYalDDtAuV"
   },
   "outputs": [],
   "source": [
    "# Perform KMeans to compress image, here K = 8 clusters\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "kmeans.fit(transform_image_for_KMeans)\n",
    "\n",
    "cluster_centroids = np.asarray(kmeans.cluster_centers_,dtype=np.uint8) \n",
    "\n",
    "# labels represent the label of each pixel and which cluster it belongs to\n",
    "labels = np.asarray(kmeans.labels_,dtype=np.uint8 )  \n",
    "labels = labels.reshape(num_rows,num_cols);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1712,
     "status": "ok",
     "timestamp": 1555278199443,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "Ngjw_z73tIcc",
    "outputId": "9237017d-5ebd-40a0-8492-4504cd544026"
   },
   "outputs": [],
   "source": [
    "compressed_image = np.ones((num_rows, num_cols, 3), dtype=np.uint8)\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "        compressed_image[r, c, :] = cluster_centroids[labels[r, c], :]\n",
    "\n",
    "cv2.imwrite(\"compressed_bunny.png\", compressed_image)\n",
    "compressed_bunny_im = cv2.imread(\"compressed_bunny.png\")\n",
    "compressed_bunny_im_corrected = cv2.cvtColor(compressed_bunny_im, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(compressed_bunny_im_corrected)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1555278628447,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "CfRDgUUKgJP1",
    "outputId": "3b4d1e37-2071-4ebb-a8d7-359d408e7d8f"
   },
   "outputs": [],
   "source": [
    "print(\"Compressed size of bunny's image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('compressed_bunny.png').st_size)/1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afwxfotz1SmS"
   },
   "source": [
    "<p>Thus, we see that we have compressed the bunny's image size to <b>48  Kilo Bytes</b> from the original <b>630 Kilo Bytes</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Woah! We have compressed the size of the bunny's <b>image by **92%</b></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "<h2 align=\"center\">Exercises</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adpNDQxU2TN6"
   },
   "source": [
    "<h2>Exercise 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTREx9FN2Yja"
   },
   "source": [
    "<p>Below, I have provided a few pictures for you to play with. Feel free to use K Means Clustering (try it out with different values of K) to compress an image. Notice how the image size varies when you increase the value of K.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1872,
     "status": "ok",
     "timestamp": 1555280725030,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "4WhRni9-5194",
    "outputId": "eaf90f71-3d75-46b8-a6c6-3ee58429ff08"
   },
   "outputs": [],
   "source": [
    "# We read a fish image here and display it\n",
    "fish_image_url = \"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/fish.png\"\n",
    "urllib.request.urlretrieve(fish_image_url, \"fish.png\") # downloads file as \"fish.png\"\n",
    "im2 = cv2.imread(\"fish.png\")\n",
    "fish_im_corrected = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(fish_im_corrected)\n",
    "print(\"Original size of fish image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('fish.png').st_size)/1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4FP-sZ89KZk"
   },
   "outputs": [],
   "source": [
    "# Write your code here to Perform K Means Clustering on the fish image \n",
    "# (stored in variable im2) and compress its size \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!---\n",
    "\n",
    "#Extracting num_rows and num_cols from fish image\n",
    "\n",
    "\n",
    "num_rows_fish = im2.shape[0]\n",
    "num_cols_fish = im2.shape[1]\n",
    "transform_fish_image_for_KMeans = im2.reshape(num_rows_fish * num_cols_fish, 3)\n",
    "\n",
    "\n",
    "#Perform KMeans to compress fish image here, feel free to choose\n",
    "#any value for K, (i.e. K < 256) for compressing the image size. Use the value\n",
    "#of K to fill the value of n_clusters\n",
    "\n",
    "\n",
    "kmeans_fish = KMeans(n_clusters=)\n",
    "kmeans_fish.fit(transform_fish_image_for_KMeans)\n",
    "cluster_centroids_fish = np.asarray(kmeans_fish.cluster_centers_,dtype=np.uint8) \n",
    "\n",
    "\n",
    "#labels represent the label of each pixel and which cluster it belongs to\n",
    "\n",
    "\n",
    "labels_fish = np.asarray(kmeans_fish.labels_,dtype=np.uint8 )  \n",
    "labels_fish = labels_fish.reshape(num_rows_fish,num_cols_fish)\n",
    "\n",
    "#After running the above code, run the code below\n",
    "   \n",
    "\n",
    "compressed_image_fish = np.ones((num_rows_fish, num_cols_fish, 3), dtype=np.uint8)\n",
    "for r in range(num_rows_fish):\n",
    "    for c in range(num_cols_fish):\n",
    "        compressed_image_fish[r, c, :] = cluster_centroids_fish[labels_fish[r, c], :]\n",
    "cv2.imwrite(\"compressed_fish.png\", compressed_image_fish)\n",
    "compressed_fish_im = cv2.imread('compressed_fish.png')\n",
    "compressed_fish_im_corrected = cv2.cvtColor(compressed_fish_im, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(compressed_fish_im_corrected) \n",
    "print(\"Compressed size of fish image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('compressed_fish.png').st_size)/1000))))\n",
    "\n",
    "\n",
    "--->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1555346993015,
     "user": {
      "displayName": "Sacchit Chadha",
      "photoUrl": "",
      "userId": "02325912782123101459"
     },
     "user_tz": 240
    },
    "id": "H8i_55p3YBBz",
    "outputId": "b7682454-8330-4a57-d23e-8ae354913b0c"
   },
   "outputs": [],
   "source": [
    "# We read a butterfly image here and display it\n",
    "butterfly_image_url = \"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/butterfly.png\"\n",
    "urllib.request.urlretrieve(butterfly_image_url, \"butterfly.png\") # downloads file as \"butterfly.png\"\n",
    "im3 = cv2.imread(\"butterfly.png\")\n",
    "butterfly_im_corrected = cv2.cvtColor(im3, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(butterfly_im_corrected)\n",
    "print(\"Original size of butterfly image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('butterfly.png').st_size)/1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to Perform K Means Clustering on the butterfly image \n",
    "# (stored in variable im3) and compress its size\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!---\n",
    "\n",
    "#Extracting num_rows and num_cols from butterfly image\n",
    "\n",
    "\n",
    "num_rows_butterfly = im3.shape[0]\n",
    "num_cols_butterfly = im3.shape[1]\n",
    "transform_butterfly_image_for_KMeans = im3.reshape(num_rows_butterfly * num_cols_butterfly, 3)\n",
    "\n",
    "\n",
    "#Perform KMeans to compress butterfly image here, feel free to choose\n",
    "#any value for K, (i.e. K < 256) for compressing the image size. Use the value\n",
    "#of K to fill the value of n_clusters**\n",
    "\n",
    "\n",
    "kmeans_butterfly = KMeans(n_clusters=)\n",
    "kmeans_butterfly.fit(transform_butterfly_image_for_KMeans)\n",
    "cluster_centroids_butterfly = np.asarray(kmeans_butterfly.cluster_centers_,dtype=np.uint8) \n",
    "\n",
    "\n",
    "#labels represent the label of each pixel and which cluster it belongs to\n",
    "\n",
    "\n",
    "labels_butterfly = np.asarray(kmeans_butterfly.labels_,dtype=np.uint8 )  \n",
    "labels_butterfly = labels_butterfly.reshape(num_rows_butterfly,num_cols_butterfly)\n",
    "\n",
    "\n",
    "#After running the above code, run the code below\n",
    "\n",
    "\n",
    "compressed_image_butterfly = np.ones((num_rows_butterfly, num_cols_butterfly, 3), dtype=np.uint8)\n",
    "for r in range(num_rows_butterfly):\n",
    "    for c in range(num_cols_butterfly):\n",
    "        compressed_image_butterfly[r, c, :] = cluster_centroids_butterfly[labels_butterfly[r, c], :]\n",
    "cv2.imwrite(\"compressed_image_butterfly.png\", compressed_image_butterfly)\n",
    "compressed_butterfly_im = cv2.imread('compressed_image_butterfly.png')\n",
    "compressed_butterfly_im_corrected = cv2.cvtColor(compressed_butterfly_im, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(compressed_butterfly_im_corrected)\n",
    "print(\"Compressed size of butterfly image is: {} Kilo Bytes\".format(str(math.ceil((os.stat('compressed_image_butterfly.png').st_size)/1000))))\n",
    "\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thank you for completing this lab!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <h2>Get IBM Watson Studio free of charge!</h2>\n",
    "    <p><a href=\"https://cocl.us/NotebooksPython101bottom\"><img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Logo/BottomAd.png\" width=\"750\" align=\"center\"></a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>About the Authors:</h3>\n",
    "\n",
    "This lab was written by <a href=\"https://www.linkedin.com/in/sacchitchadha/\" target=\"_blank\" >Sacchit Chadha</a> and revised by Nayef Abou Tayoun\n",
    "\n",
    "<p><a href=\"https://www.linkedin.com/in/sacchitchadha/\" target=\"_blank\">Sacchit Chadha</a> is a Software Engineer at IBM, and is a rising senior pursuing a Bachelors Degree in Computer Science from the University of Waterloo. His work at IBM is focused on Computer Vision, Cloud Computing and Blockchain.</p>\n",
    "<p>Nayef Abou Tayoun is a Cognitive Data Scientist at IBM, and is pursuing a Master's degree in Artificial Intelligence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p>Copyright &copy; 2019 IBM Developer Skills Network. This notebook and its source code are released under the terms of the <a href=\"https://cognitiveclass.ai/mit-license/\">MIT License</a>.</p>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ImageCompressionKMeans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
